# ==========================================
# ‡πÑ‡∏ü‡∏•‡πå: llm_analyzer.py
# ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: ‡πÉ‡∏ä‡πâ LLM Vision Model ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
# ==========================================

import os
import base64
import json
from pathlib import Path
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from datetime import datetime

class LLMTrainingAnalyzer:
    """
    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢ LLM Vision Model
    - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏à‡∏≤‡∏Å training metrics
    - ‡∏™‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    - ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡πà‡∏≠
    """
    
    def __init__(self, api_key=None, model="gemini-2.0-flash-exp"):
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á LLM Analyzer
        
        Parameters:
        -----------
        api_key : str
            Google AI API Key (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å environment variable)
        model : str
            ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ (default: gemini-2.0-flash-exp)
        """
        self.api_key = api_key or os.getenv('GOOGLE_API_KEY')
        self.model = model
        self.metrics_history = []
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ API key ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not self.api_key:
            print("‚ö†Ô∏è Warning: GOOGLE_API_KEY not found. LLM analysis will be disabled.")
            print("   Set it with: export GOOGLE_API_KEY='your-api-key'")
            self.enabled = False
        else:
            self.enabled = True
            # Import Google AI SDK
            try:
                import google.generativeai as genai
                genai.configure(api_key=self.api_key)
                self.genai = genai
                print("‚úÖ LLM Analyzer initialized successfully!")
            except ImportError:
                print("‚ö†Ô∏è google-generativeai not installed. Run: pip install google-generativeai")
                self.enabled = False
    
    def log_metrics(self, iteration, metrics):
        """
        ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metrics ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
        
        Parameters:
        -----------
        iteration : int
            ‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        metrics : dict
            ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metrics ‡πÄ‡∏ä‡πà‡∏ô loss, reward, etc.
        """
        metrics['iteration'] = iteration
        metrics['timestamp'] = datetime.now().isoformat()
        self.metrics_history.append(metrics)
    
    def create_training_chart(self, save_path='training_progress.png'):
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
        
        Parameters:
        -----------
        save_path : str
            ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü
            
        Returns:
        --------
        str : path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
        """
        if not self.metrics_history:
            print("‚ö†Ô∏è No metrics to plot yet.")
            return None
        
        df = pd.DataFrame(self.metrics_history)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü 2x2
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Training Progress Analysis', fontsize=16, fontweight='bold')
        
        # 1. Loss over time
        if 'loss' in df.columns:
            axes[0, 0].plot(df['iteration'], df['loss'], 'b-', linewidth=2)
            axes[0, 0].set_title('Policy Loss', fontsize=12, fontweight='bold')
            axes[0, 0].set_xlabel('Iteration')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True, alpha=0.3)
        
        # 2. Value Loss
        if 'value_loss' in df.columns:
            axes[0, 1].plot(df['iteration'], df['value_loss'], 'r-', linewidth=2)
            axes[0, 1].set_title('Value Loss', fontsize=12, fontweight='bold')
            axes[0, 1].set_xlabel('Iteration')
            axes[0, 1].set_ylabel('Value Loss')
            axes[0, 1].grid(True, alpha=0.3)
        
        # 3. Entropy Loss
        if 'entropy_loss' in df.columns:
            axes[1, 0].plot(df['iteration'], df['entropy_loss'], 'g-', linewidth=2)
            axes[1, 0].set_title('Entropy Loss (Exploration)', fontsize=12, fontweight='bold')
            axes[1, 0].set_xlabel('Iteration')
            axes[1, 0].set_ylabel('Entropy')
            axes[1, 0].grid(True, alpha=0.3)
        
        # 4. Explained Variance
        if 'explained_variance' in df.columns:
            axes[1, 1].plot(df['iteration'], df['explained_variance'], 'm-', linewidth=2)
            axes[1, 1].set_title('Explained Variance', fontsize=12, fontweight='bold')
            axes[1, 1].set_xlabel('Iteration')
            axes[1, 1].set_ylabel('Variance')
            axes[1, 1].grid(True, alpha=0.3)
            axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"üìä Training chart saved to: {save_path}")
        return save_path
    
    def analyze_with_llm(self, chart_path, current_iteration, total_iterations):
        """
        ‡∏™‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
        
        Parameters:
        -----------
        chart_path : str
            path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏£‡∏≤‡∏ü
        current_iteration : int
            ‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        total_iterations : int
            ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            
        Returns:
        --------
        dict : ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å LLM
        """
        if not self.enabled:
            return {
                'status': 'disabled',
                'message': 'LLM analysis is disabled. Please set GOOGLE_API_KEY.'
            }
        
        try:
            # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô base64
            with open(chart_path, 'rb') as f:
                image_data = f.read()
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM
            prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô Reinforcement Learning ‡πÅ‡∏•‡∏∞ Trading AI

‡∏Å‡∏£‡∏≤‡∏ü‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• PPO (Proximal Policy Optimization) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏î Forex

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:**
- Iteration ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: {current_iteration}/{total_iterations} ({current_iteration/total_iterations*100:.1f}%)
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô metrics ‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {len(self.metrics_history)} ‡∏£‡∏≠‡∏ö

**‡∏Å‡∏£‡∏≤‡∏ü‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:**
1. **Policy Loss** (‡∏ö‡∏ô‡∏ã‡πâ‡∏≤‡∏¢) - ‡∏Ñ‡πà‡∏≤ loss ‡∏Ç‡∏≠‡∏á policy network
2. **Value Loss** (‡∏ö‡∏ô‡∏Ç‡∏ß‡∏≤) - ‡∏Ñ‡πà‡∏≤ loss ‡∏Ç‡∏≠‡∏á value network
3. **Entropy Loss** (‡∏•‡πà‡∏≤‡∏á‡∏ã‡πâ‡∏≤‡∏¢) - ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à (exploration)
4. **Explained Variance** (‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤) - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á value function

**‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON:**

{{
    "overall_status": "excellent/good/fair/poor/critical",
    "analysis": {{
        "policy_loss": "‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå policy loss (‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°, ‡∏õ‡∏±‡∏ç‡∏´‡∏≤, ‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï)",
        "value_loss": "‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå value loss",
        "entropy": "‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå entropy (‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à)",
        "variance": "‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå explained variance"
    }},
    "issues": [
        "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)"
    ],
    "recommendations": [
        "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏ï‡πà‡∏≠ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)"
    ],
    "should_continue": true/false,
    "reason": "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏¢‡∏∏‡∏î",
    "estimated_completion": "‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡∏≠‡∏µ‡∏Å‡∏Å‡∏µ‡πà iteration"
}}

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:**
- ‡∏ñ‡πâ‡∏≤ loss ‡∏•‡∏î‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á = ‡∏î‡∏µ
- ‡∏ñ‡πâ‡∏≤ loss ‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏•‡∏á‡∏°‡∏≤‡∏Å = ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ learning rate ‡∏´‡∏£‡∏∑‡∏≠ instability
- Entropy ‡∏Ñ‡∏ß‡∏£‡∏•‡∏î‡∏•‡∏á‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ (‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤ policy ‡∏Å‡∏≥‡∏•‡∏±‡∏á converge)
- Explained Variance ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ 1.0 (‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤ value function ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ)
"""
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM
            model = self.genai.GenerativeModel(self.model)
            
            # Upload image
            image_part = {
                'mime_type': 'image/png',
                'data': image_data
            }
            
            response = model.generate_content([prompt, image_part])
            
            # Parse response
            response_text = response.text
            
            # ‡∏•‡∏≠‡∏á‡πÅ‡∏¢‡∏Å JSON ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å response
            try:
                # ‡∏´‡∏≤ JSON block
                if '```json' in response_text:
                    json_start = response_text.find('```json') + 7
                    json_end = response_text.find('```', json_start)
                    json_text = response_text[json_start:json_end].strip()
                elif '```' in response_text:
                    json_start = response_text.find('```') + 3
                    json_end = response_text.find('```', json_start)
                    json_text = response_text[json_start:json_end].strip()
                else:
                    json_text = response_text
                
                analysis = json.loads(json_text)
                analysis['raw_response'] = response_text
                analysis['status'] = 'success'
                
            except json.JSONDecodeError:
                # ‡∏ñ‡πâ‡∏≤ parse ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á raw text ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ
                analysis = {
                    'status': 'success',
                    'raw_response': response_text,
                    'overall_status': 'unknown',
                    'recommendations': ['‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô raw_response']
                }
            
            return analysis
            
        except Exception as e:
            return {
                'status': 'error',
                'message': f'Error during LLM analysis: {str(e)}'
            }
    
    def print_analysis(self, analysis):
        """
        ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
        
        Parameters:
        -----------
        analysis : dict
            ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å LLM
        """
        print("\n" + "="*80)
        print("ü§ñ LLM TRAINING ANALYSIS")
        print("="*80)
        
        if analysis['status'] == 'disabled':
            print(f"‚ö†Ô∏è {analysis['message']}")
            return
        
        if analysis['status'] == 'error':
            print(f"‚ùå {analysis['message']}")
            return
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
        status_emoji = {
            'excellent': 'üåü',
            'good': '‚úÖ',
            'fair': '‚ö†Ô∏è',
            'poor': '‚ö†Ô∏è',
            'critical': 'üö®'
        }
        
        overall = analysis.get('overall_status', 'unknown')
        emoji = status_emoji.get(overall, '‚ùì')
        print(f"\n{emoji} ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°: {overall.upper()}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
        if 'analysis' in analysis:
            print("\nüìä ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
            for key, value in analysis['analysis'].items():
                print(f"  ‚Ä¢ {key}: {value}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö
        if 'issues' in analysis and analysis['issues']:
            print("\n‚ö†Ô∏è ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:")
            for i, issue in enumerate(analysis['issues'], 1):
                print(f"  {i}. {issue}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
        if 'recommendations' in analysis and analysis['recommendations']:
            print("\nüí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
            for i, rec in enumerate(analysis['recommendations'], 1):
                print(f"  {i}. {rec}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏™‡∏£‡∏∏‡∏õ
        if 'should_continue' in analysis:
            should_continue = analysis['should_continue']
            reason = analysis.get('reason', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•')
            
            if should_continue:
                print(f"\n‚úÖ ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠: {reason}")
            else:
                print(f"\nüõë ‡∏Ñ‡∏ß‡∏£‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏ô: {reason}")
        
        if 'estimated_completion' in analysis:
            print(f"üìà ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£: {analysis['estimated_completion']}")
        
        print("\n" + "="*80 + "\n")
    
    def save_analysis(self, analysis, filepath='llm_analysis.json'):
        """
        ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
        
        Parameters:
        -----------
        analysis : dict
            ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        filepath : str
            ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        """
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)
        print(f"üíæ Analysis saved to: {filepath}")


# ==========================================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
# ==========================================

def example_usage():
    """
    ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLM Analyzer
    """
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer
    analyzer = LLMTrainingAnalyzer()
    
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metrics
    for i in range(1, 26):
        metrics = {
            'loss': -0.02 + np.random.normal(0, 0.01),
            'value_loss': 0.03 + np.random.normal(0, 0.005),
            'entropy_loss': -1.0 + i * 0.02 + np.random.normal(0, 0.05),
            'explained_variance': 0.3 + i * 0.02 + np.random.normal(0, 0.05)
        }
        analyzer.log_metrics(i, metrics)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü
    chart_path = analyzer.create_training_chart()
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ LLM
    if chart_path:
        analysis = analyzer.analyze_with_llm(chart_path, current_iteration=25, total_iterations=50)
        analyzer.print_analysis(analysis)
        analyzer.save_analysis(analysis)


if __name__ == "__main__":
    example_usage()
