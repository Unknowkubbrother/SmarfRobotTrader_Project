# ==========================================
# ‡πÑ‡∏ü‡∏•‡πå: train_ppo.py
# ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• PPO (Proximal Policy Optimization) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏î Forex
# ==========================================

import torch
import gymnasium as gym
import pandas as pd
import numpy as np
from stable_baselines3 import PPO  # ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏° Reinforcement Learning
from stable_baselines3.common.vec_env import DummyVecEnv  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡πà‡∏≠ environment
import os
from trading_env import TradingEnv  # Custom trading environment ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á
import ta  # ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Technical Indicators
from sklearn.preprocessing import StandardScaler  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
import joblib  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å scaler

def load_and_process_data(filepath, save_scaler=True):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    - ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å CSV
    - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Technical Indicators
    - Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å scaler ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ backtest
    """
    print("‚è≥ Loading data...")
    try:
        df = pd.read_csv(filepath)
    except FileNotFoundError:
        print("‚ùå CSV file not found.")
        return None, None

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå time ‡πÄ‡∏õ‡πá‡∏ô datetime ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤
    if 'time' in df.columns:
        df['time'] = pd.to_datetime(df['time'])
        df = df.sort_values('time').reset_index(drop=True)
    
    print("üîß Advanced Feature Engineering...")
    
    # ==========================================
    # 1. Trend Indicators (‡∏ï‡∏±‡∏ß‡∏ö‡∏≠‡∏Å‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°)
    # ==========================================
    # EMA (Exponential Moving Average) - ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡∏ö‡πÄ‡∏≠‡πá‡∏Å‡∏ã‡πå‡πÇ‡∏û‡πÄ‡∏ô‡∏ô‡πÄ‡∏ä‡∏µ‡∏¢‡∏•
    df['ema_12'] = ta.trend.EMAIndicator(close=df['close'], window=12).ema_indicator()
    df['ema_26'] = ta.trend.EMAIndicator(close=df['close'], window=26).ema_indicator()
    
    # MACD (Moving Average Convergence Divergence) - ‡∏ï‡∏±‡∏ß‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà
    df['macd'] = ta.trend.MACD(close=df['close']).macd()
    df['macd_signal'] = ta.trend.MACD(close=df['close']).macd_signal()
    
    # ADX (Average Directional Index) - ‡∏ï‡∏±‡∏ß‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°
    df['adx'] = ta.trend.ADXIndicator(high=df['high'], low=df['low'], close=df['close']).adx()
    
    # ==========================================
    # 2. Momentum Indicators (‡∏ï‡∏±‡∏ß‡∏ö‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡∏±‡∏°)
    # ==========================================
    # RSI (Relative Strength Index) - ‡∏ï‡∏±‡∏ß‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏£‡∏á‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ó‡∏ò‡πå (0-100)
    df['rsi'] = ta.momentum.RSIIndicator(close=df['close']).rsi()
    
    # Stochastic Oscillator - ‡∏ï‡∏±‡∏ß‡∏ö‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡∏±‡∏°‡πÅ‡∏ö‡∏ö Stochastic
    df['stoch_k'] = ta.momentum.StochasticOscillator(high=df['high'], low=df['low'], close=df['close']).stoch()
    
    # ==========================================
    # 3. Volatility Indicators (‡∏ï‡∏±‡∏ß‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô)
    # ==========================================
    # Bollinger Bands - ‡πÅ‡∏ñ‡∏ö‡∏ö‡∏≠‡∏•‡∏•‡∏¥‡∏á‡πÄ‡∏à‡∏≠‡∏£‡πå (‡∏ö‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß)
    df['bb_upper'] = ta.volatility.BollingerBands(close=df['close']).bollinger_hband()
    df['bb_lower'] = ta.volatility.BollingerBands(close=df['close']).bollinger_lband()
    
    # ATR (Average True Range) - ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á (‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô)
    df['atr'] = ta.volatility.AverageTrueRange(high=df['high'], low=df['low'], close=df['close']).average_true_range()
    
    # ==========================================
    # 4. Custom Features (‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á)
    # ==========================================
    # Return - ‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå
    df['return'] = df['close'].pct_change()
    
    # Log Return - ‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡πÅ‡∏ö‡∏ö logarithm (‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥)
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏≤‡∏Å indicators (‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô stationary)
    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å EMA 12
    df['dist_ema12'] = (df['close'] - df['ema_12']) / df['ema_12']
    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Bollinger Band ‡∏ö‡∏ô
    df['dist_bb_upper'] = (df['bb_upper'] - df['close']) / df['close']
    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Bollinger Band ‡∏•‡πà‡∏≤‡∏á
    df['dist_bb_lower'] = (df['close'] - df['bb_lower']) / df['close']
    
    # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ NaN (‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators)
    df = df.dropna().reset_index(drop=True)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° close, time, open, high, low)
    feature_cols = [
        'macd', 'macd_signal', 'adx', 'rsi', 'stoch_k', 
        'atr', 'return', 'log_return',
        'dist_ema12', 'dist_bb_upper', 'dist_bb_lower'
    ]
    
    print(f"   Selected {len(feature_cols)} features: {feature_cols}")

    # ==========================================
    # Standardize Features (‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
    # ==========================================
    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ = 0 ‡πÅ‡∏•‡∏∞ standard deviation = 1
    # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Neural Network ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
    scaler = StandardScaler()
    df[feature_cols] = scaler.fit_transform(df[feature_cols])
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Scaler ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Backtest (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ scaler ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
    if save_scaler:
        joblib.dump(scaler, 'scaler.pkl')
    
    return df, feature_cols

def train_ppo(use_llm_analysis=True, analysis_interval=5):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• PPO
    - ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    - ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô Train/Test
    - ‡∏™‡∏£‡πâ‡∏≤‡∏á Environment
    - ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏û‡∏£‡πâ‡∏≠‡∏° LLM Analysis)
    - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    
    Parameters:
    -----------
    use_llm_analysis : bool
        ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLM Analysis ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (default: True)
    analysis_interval : int
        ‡∏ó‡∏∏‡∏Å‡πÜ ‡∏Å‡∏µ‡πà iteration ‡∏à‡∏∞‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå (default: 5)
    """
    # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df, feature_cols = load_and_process_data('EURUSD_2009_to_present.csv')
    if df is None: return

    # ==========================================
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: 80% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô, 20% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    # ==========================================
    split_idx = int(len(df) * 0.8)
    train_df = df.iloc[:split_idx].reset_index(drop=True)  # 80% ‡πÅ‡∏£‡∏Å
    test_df = df.iloc[split_idx:].reset_index(drop=True)   # 20% ‡∏´‡∏•‡∏±‡∏á
    
    print(f"üìä Total Data: {len(df)}")
    print(f"   - Train: {len(train_df)}")
    print(f"   - Test:  {len(test_df)}")
    
    # ==========================================
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Trading Environment
    # ==========================================
    # ‡∏™‡πà‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ + close (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì PnL) + time (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö logging)
    env_cols = feature_cols + ['close', 'time']
    train_env = DummyVecEnv([lambda: TradingEnv(train_df[env_cols])])
    
    # ==========================================
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á LLM Analyzer (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)
    # ==========================================
    llm_analyzer = None
    if use_llm_analysis:
        from llm_analyzer import LLMTrainingAnalyzer
        llm_analyzer = LLMTrainingAnalyzer()
        print(f"ü§ñ LLM Analysis enabled (every {analysis_interval} iterations)")
    
    # ==========================================
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• PPO
    # ==========================================
    print("ü§ñ Initializing PPO model...")
    # MlpPolicy = Multi-Layer Perceptron (Neural Network ‡πÅ‡∏ö‡∏ö‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤)
    # verbose=1 = ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ó‡∏£‡∏ô
    # tensorboard_log = ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å log ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏π‡πÉ‡∏ô TensorBoard
    model = PPO("MlpPolicy", train_env, verbose=1, tensorboard_log="./ppo_trading_tensorboard/")
    
    # ==========================================
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏û‡∏£‡πâ‡∏≠‡∏° LLM Analysis)
    # ==========================================
    print("üöÄ Starting training...")
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô timesteps
    total_timesteps = 50000
    timesteps_per_iteration = 2048  # PPO default
    total_iterations = total_timesteps // timesteps_per_iteration
    
    try:
        # ‡πÄ‡∏ó‡∏£‡∏ô‡∏ó‡∏µ‡∏•‡∏∞ iteration ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏≤‡∏á‡πÑ‡∏î‡πâ
        for iteration in range(1, total_iterations + 1):
            # ‡πÄ‡∏ó‡∏£‡∏ô 1 iteration
            model.learn(total_timesteps=timesteps_per_iteration, reset_num_timesteps=False)
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metrics ‡∏à‡∏≤‡∏Å logger (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ LLM analyzer)
            if llm_analyzer and llm_analyzer.enabled:
                try:
                    # ‡∏î‡∏∂‡∏á metrics ‡∏à‡∏≤‡∏Å model logger
                    logger = model.logger
                    if hasattr(logger, 'name_to_value'):
                        metrics = {}
                        for key, value in logger.name_to_value.items():
                            if 'train/' in key:
                                clean_key = key.replace('train/', '')
                                metrics[clean_key] = value
                        
                        if metrics:
                            llm_analyzer.log_metrics(iteration, metrics)
                except Exception as e:
                    print(f"‚ö†Ô∏è Warning: Could not log metrics: {e}")
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ LLM ‡∏ó‡∏∏‡∏Å‡πÜ analysis_interval iterations
            if llm_analyzer and llm_analyzer.enabled and iteration % analysis_interval == 0:
                print(f"\n{'='*80}")
                print(f"üîç Running LLM Analysis at iteration {iteration}/{total_iterations}")
                print(f"{'='*80}")
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü
                chart_path = llm_analyzer.create_training_chart(
                    save_path=f'training_progress_iter_{iteration}.png'
                )
                
                # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ LLM
                if chart_path:
                    analysis = llm_analyzer.analyze_with_llm(
                        chart_path, 
                        current_iteration=iteration,
                        total_iterations=total_iterations
                    )
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                    llm_analyzer.print_analysis(analysis)
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•
                    llm_analyzer.save_analysis(
                        analysis, 
                        filepath=f'llm_analysis_iter_{iteration}.json'
                    )
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ LLM ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    if analysis.get('should_continue') == False:
                        print("\nüõë LLM recommends stopping training.")
                        user_input = input("Do you want to stop? (y/n): ")
                        if user_input.lower() == 'y':
                            print("‚èπÔ∏è Training stopped by user based on LLM recommendation.")
                            break
        
        print("‚úÖ Training finished!")
        
        # ==========================================
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à
        # ==========================================
        if llm_analyzer and llm_analyzer.enabled and llm_analyzer.metrics_history:
            print(f"\n{'='*80}")
            print("üîç Final LLM Analysis")
            print(f"{'='*80}")
            
            chart_path = llm_analyzer.create_training_chart(save_path='training_progress_final.png')
            if chart_path:
                final_analysis = llm_analyzer.analyze_with_llm(
                    chart_path,
                    current_iteration=total_iterations,
                    total_iterations=total_iterations
                )
                llm_analyzer.print_analysis(final_analysis)
                llm_analyzer.save_analysis(final_analysis, filepath='llm_analysis_final.json')
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Training stopped manually.")
        
    # ==========================================
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
    # ==========================================
    model.save("ppo_trading_eurusd")
    print("üíæ Model saved to ppo_trading_eurusd.zip")
    
    # ==========================================
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Backtesting
    # ==========================================
    test_df.to_csv('test_data.csv', index=False)
    print("üíæ Saved test data for backtesting.")

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
if __name__ == "__main__":
    # ‡πÄ‡∏ó‡∏£‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏° LLM Analysis (‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏∏‡∏Å‡πÜ 5 iterations)
    train_ppo(use_llm_analysis=True, analysis_interval=5)
